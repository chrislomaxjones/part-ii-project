\chapter{Preparation}

This chapter describes the necessary background material required to understand Paxos; first in the simpler case of agreeing on one value and then going on to the Multi--decree case for agreeing on a sequence of values. From this a set of requirements for the project is established. Finally the software engineering aspects of the project are discussed including the choice of tools, build processes and third party libraries.

\section{Theoretical background}

\subsection{Assumptions of the environment}
\label{section-assumptions}
When considering developing a system with distributed consensus, it is necessary to consider the assumptions made in the environment in which such a system will operate. This is to ensure there is enough functionality embedded in the system to ensure that consensus is reached under the given set of assumptions. \\

A \emph{process} (or networked process) is an instance of the program running on a networked machine in a distributed system. Assumptions of these processes that participate in the system:

\begin{itemize}
  \item Processes can undergo \emph{crash failures}. A crash failure is defined as a process terminating but not entering an invalid state.
  \item Processes may recover from crash failures. They can rejoin the system in some valid state. 
  \item Processes operate at arbitrary speeds. This cannot be distinguished by other processes from arbitrarily long delays in the network.
\end{itemize}

Assumptions of the network over which these processes communicate:

\begin{itemize}
  \item All processes can communicate with one another.
  \item The network environment is \emph{asynchronous}. That is, messages may take an arbitrarily long time to be delivered.
  \item Messages may be re--ordered upon delivery.
  \item Messages may be duplicated in the network.
  \item Messages may be dropped from the network.
  \item Messages are not corrupted or modified in the network.
  \item A message that is received by one process was, at some point in the past, sent by another process.
\end{itemize}

The last two assumptions preclude us from handling what are known generally as \emph{Byzantine failures}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Aim of consensus}

With distributed consensus, we wish for a network of processes to agree on some value. It is assumed that processes can somehow propose values to other processes. The goal of distributed consensus, given a number of processes that can each propose some value $v$, is that one proposed value is chosen. This is the \emph{single--decree} case; only one value is proposed by each process and only one is chosen. \\

In the \emph{multi--decree} case, agreement is reached over a sequence of values. Each process will propose a sequence of values $v_1, v_2, \ldots, v_n$ and the goal of consensus is to choose one such sequence. This multi--decree case allows for \emph{state machine replication} to be employed.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{State machine replication}

A desirable goal of distributed computing is to replicate an application across a set of machines so that each \emph{replica} has the same strongly--consistent application state. This technique is referred to as State Machine Replication (SMR); it leads to both increased fault tolerance and higher availability. Multi--decree consensus algorithms provide a means of performing SMR. \\

Each process participating in the consensus algorithm runs the replicated state machine application and starts in the same state. By treating the values proposed as \emph{commands} to perform state transitions, running a consensus algorithm causes each process to receive the same sequence of commands $c_1, c_2, \ldots, c_n$. Each process thus performs the same sequence of transitions from the same starting state and is therefore maintains a replica of the application. \\

Before considering how to implement SMR in the multi--decree case, it is useful to examine how Paxos operates in the simpler single--decree case.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Single--decree Paxos}

\begin{table}
  \centering
  \begin{tabular}{ l | p{8cm} | c }
    \textbf{Role} & \textbf{Purpose} & \textbf{Number required} \\ \hline
    Proposer & Propose values to acceptors. & $f+1$ \\
                     & Send prepare requests with proposal numbers. & \\ [.5\normalbaselineskip] \hline
    Acceptor & Decide whether to \emph{adopt} a proposal based on its proposal number & $2f+1$ \\
                     & Decide whether to \emph{accept} a proposal based on a higher numbered proposal having arriving. & \\ [.5\normalbaselineskip] \hline
    Learner & Learn value chosen by majority of acceptors & $f + 1$ \\ [.5\normalbaselineskip]
  \end{tabular}
  \caption{Summary of the roles in single--decree Paxos. In this description the system can tolerate the failure of up to $f$ of each given role.}
\label{table:role-summary}
\end{table}

Single--decree Paxos is the variant of the algorithm that allows for a single value to be chosen from a set of proposals and provides a foundation for the multi--decree case that will be considered next. The terminology used here follows Lamport's paper \cite{paxos-made-simple} describing the single--decree protocol in simple terms. Processes take the roles of \emph{proposers}, \emph{acceptors} and \emph{learners}, each of which has a designated task in the algorithm. In reality these roles are often co--located within a single process but it is simpler to consider each separately.  The purpose of each role and the number of each role required to tolerate $f$ failures is summarised in Table \ref{table:role-summary}.  \\

Proposers that wish to propose a value $v$ submit proposals of the form $\left(n,v\right)$, where $n \in \mathbb{N}$ is called a \emph{proposal number}. Each proposer may propose one proposal at a time and may only use strictly increasing proposal numbers. Furthermore, each proposer must use a disjoint set of proposal numbers. The Paxos algorithm is divided into a number of stages described below. \\

\textbf{Phase 1a (Prepare phase)} A proposer wishing to propose a value first sends a \texttt{prepare($n$)} message to a majority of the set of acceptors, where $n$ is the highest proposal number it has used so far. \\

\textbf{Phase 1b (Promise phase)} In this phase an acceptor receiving a \texttt{prepare($n$)} message must decide whether or not to \emph{adopt} this proposal number. Adopting a proposal number is the act of promising not to accept a future proposal number $n'$ such that $n' < n$. The acceptor will adopt $n$ if it is the highest proposal number it has received thus far, in which case it will reply to the proposer with a \texttt{promise($n''$,$v$)} message, where $n''$ is the highest proposal number it has previously accepted and $v$ is the corresponding proposal's value. Otherwise, it can simply ignore the proposer or send a \texttt{NACK} message so the proposer can abandon the proposal. \\

\textbf{Phase 2a (Accept phase)} Upon receipt of a \texttt{promise($n$,$v$)} message from a majority of acceptors, the proposer replies to each with an \texttt{accept($n'$,$v'$)} message, where $n'$ is the highest proposal number returned by the acceptors in the promise phase and $v'$ is its corresponding value. \\

\textbf{Phase 2b (Commit phase)} An acceptor receiving an \texttt{accept($n$,$v$)} message from a proposer will decide whether to commit the proposal for $v$. If the acceptor hasn't made a promise to adopt a proposal number higher than $n$, then it will commit $v$, otherwise it will ignore this message or send a \texttt{NACK} to the proposer. \\

Figures \ref{fig:single-paxos-1} and \ref{fig:single-paxos-2} show two example message flows between proposers and acceptors in the single Paxos protocol. \\

Once this process is completed, a majority of the acceptors will have chosen the same proposed value. Learners are required to each learn the value chosen by the majority. A number of different methods can be employed to achieve this. The simplest is to have acceptors chosen broadcast chosen values to the learners. \\

\begin{figure}
  \centering
  \input{include/single-paxos.latex}
  \caption{Timing diagram showing a single proposer $p_1$ committing a value $v$ with three acceptors $a_1$, $a_2$ and $a_3$}
  \label{fig:single-paxos-1}  
\end{figure}

\begin{figure}
  \centering
  \input{include/single-paxos-2.latex}
  \caption{Timing diagram showing a proposer $p_1$ being preempted by acceptors $a_1$, $a_2$ and $a_3$ having already adopted a higher proposal number submitted previously by $p_2$}
  \label{fig:single-paxos-2}  
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Multi--decree Paxos}
\label{subsection:multi-decree-paxos}

Single--decree Paxos can be naively extended by allowing proposers to propose values one at a time. However, this is wasteful as it requires that proposers send \texttt{prepare} messages for each proposal they wish to make. Van Renesse et al \cite{VanRenesse:2015:PMM:2737799.2673577} describes Multi--Paxos with an emphasis on use for state machine replication that forms the basis of the description that follows. In this paper the roles of the processes are changed to emphasise the purpose of the system for SMR. \emph{Replicas} are introduced to implicitly act as the learners and maintain the replicated state machine. \emph{Clients} are introduced as a means to externally submit commands to the replicas. Proposers are referred to as \emph{leaders} as each takes the lead over some set of \emph{ballots}. The new roles and their correspondence to the single--decree roles are summarised in Table \ref{table:multi-role-summary}.

\begin{table}
\centering
\begin{tabular}{l  | l | p{6cm} | c }
   \textbf{Multi--Paxos} & \textbf{Single--decree} & \textbf{Purpose} & \textbf{Number} \\
   \textbf{role} & \textbf{equivalent} & & \textbf{required} \\
    \hline
   Client & N/A & Send commands to replicas and receive responses & $ N/A $ \\ \hline
  
   Replica & Learner & Receive requests from clients. &  \\
                 & & Serialise proposals and send to leaders. & $f + 1$ \\
                 & & Receive decisions and apply to the replicated application state. & \\
                 & & Handle reconfiguration of set of leaders & \\ \hline
  
  Leader & Proposer & Request acceptors adopt ballots. & $f + 1$ \\
               & & Secure adoption of ballots in phase 1 of synod protocol & \\
               & & Secure acceptance of ballots in phase 2 &  \\ \hline
               
  Acceptor & Acceptor & Adopt the highest ballot they have received & $2f + 1$ \\
                   & & Accept pvalues of ballot they have adopted & \\
                   & & Fault tolerant distributed memory of pvalues &  \\
\end{tabular}
\caption{Summary of the roles in Multi Paxos. In this description the system can tolerate the failure of up to $f$ of each given role. Clients do not explicitly participate in the protocol and so there is no requirement on any number being live at any given time.}
\label{table:multi-role-summary}
\end{table}

\subsubsection{Clients}

The purpose of clients is to allow for commands to be sent externally to the system which can then be formed into proposals internally. This allows the system to behave in a manner more like that of a typically deployed distributed system (with a client / server architecture) and provides a degree of failure transparency. \\

A command $c$ takes the form $\left( \kappa, \mathrm{\emph{cid}}, \mathrm{\emph{op}} \right)$, where $\kappa$ is a unique identifier for the client, \emph{cid} is a unique identifier for the command and \emph{op} is the operation to be performed. Clients broadcast a \texttt{request($c$)} message to the replicas and each is issued a \texttt{response(}\emph{cid}\texttt{,}\emph{result}\texttt{)} when consensus is reached and it has been applied to each replica's application state.

\subsubsection{Replicas}

Replicas receive commands and attempt to serialise them by converting each command $c$ into a proposal $\left(s,c\right)$, where $s \in \mathbb{N}$ is a \emph{slot number}. The slot number describes the ordering of the sequence in which commands should be committed; this is not to be confused with the proposal number $n$ in the single--decree protocol. \\

Different replicas may form different sequences of proposals and so broadcast a \texttt{propose($s$,$c$)} message to the leaders and await a \texttt{decision($s'$,$c'$)} message. The resulting decision may differ in its slot number and so the replica may have to re--propose the command. Upon receipt of decisions the replica will apply the associated operation to the application state, maintaining the replicated application.

\subsubsection{Ballots and pvalues}

Ballots are the structure over which leaders and acceptors operate. Ballots provide indirection, allowing leaders to secure agreement with acceptors for a number of proposals with different slot numbers, or for a given slot to be targeted by different ballots. This allows for a leader to perform the first phase of the synod protocol independently of having received any new proposals. It also increases the ability to execute the protocol concurrently for a number of slots at once. \\

Each ballot is uniquely identified by a \emph{ballot number}. These are either pairs $\left(r, \lambda\right)$ consisting of a round number $r \in \mathbb{N}$ and a leader identifier $\lambda$, or a specially designated least ballot number $\bot$. \\

\emph{Pvalues} associate a ballot number with a proposal. They are triples $\left(b, s, c \right)$ consisting of a ballot number, a slot number and a command. These are analogous to to the $\left( n, v \right)$ pairs used in the single--decree case, except now by encoding a leader's identifier directly in the ballot number each leader will have a disjoint set of ballots. \\

We require ballot numbers be totally ordered so that acceptors can compare them when choosing whether to adopt or accept. Letting $\mathcal{B}$ denote the set of all ballot numbers, we define the relation $\leq_{\mathcal{B}} \ \in \mathcal{B} \times \mathcal{B}$ which satisfies the following two conditions:

\begin{gather*}
  \forall \left( n, \lambda \right), \left( n', \lambda' \right) \in \mathcal{B} .
 \ \left( n, \lambda \right) \leq_{\mathcal{B}} \left( n', \lambda' \right) \iff
   \left ( n \leq n' \right) \vee \left( n = n' \wedge \lambda \leq_{\Lambda} \lambda' \right) \\
\forall \ b \in \mathcal{B} \ . \ \bot \leq_{\mathcal{B}} b
\end{gather*}  

This implies that we require leader identifiers be equipped with a total order relation  $\leq_{\Lambda}$ as well.

\subsubsection{Quorums}

Unlike replicas, acceptors do not each attempt to store their own consistent copies of decisions. Instead, it is required that at least a majority of the acceptors have in their memory a committed proposal. This is so that if any minority of the acceptors crash then there is still at least one acceptor with memory of the decision. A subset of the acceptors  $Q \subseteq \mathcal{A}$, where $|\mathcal{A}| = 2f + 1$ for some $f \in \mathbb{N}$, is called a \emph{majority quorum} or just a \emph{quorum} if $|Q| = f + 1$. \\

Hence at each phase of the synod protocol leaders broadcast their message to all acceptors and wait for a quorum of responses. This guarantees that if any minority of the acceptors fail in the future then at least one will have retained the result of the current round of the protocol.

\subsubsection{The Synod Protocol}

The synod protocol is undertaken by the leaders and acceptors in order to decide the slot to which each command is committed. The protocol proceeds in two phases similarly to the single--decree case except now leaders and acceptors operate over pvalues. \\

Acceptors maintain a ballot number in their state their represents the last ballot number they have \emph{adopted}. Adopting a ballot number represents a promise not to accept any pvalues that do not have that ballot number, ensuring acceptors do not accept conflicting pvalues. Acceptors \emph{accept} a pvalue by adding it to the set of pvalues they have already accepted. The algorithm requires that if two acceptors $\alpha, \alpha' \in \mathcal{A}$ have accepted $(b,s,c)$ and $(b,s,c')$ respectively then $c = c'$. \\

In the absence of receiving any \texttt{propose($s$,$c$)} messages from replicas, leaders attempt to secure an initial ballot with ballot number $\left(0, \lambda_k)$, where $\lambda_k$ is the identifier of the $k^{\text{\tiny th}}$ leader. They do this by broadcasting a \texttt{phase1a($b$)} message in the same format as of that below. \\

\textbf{Phase 1a} Leaders attempt to secure adoption of a ballot $b$ by broadcasting a \texttt{phase1a($b$)} message to the acceptors. \\

\textbf{Phase 1b} Acceptors receiving a \texttt{phase1a($b$)} compare $b$ to the highest ballot number $b'$ they have adopted thus far. This is initially $\bot$ so acceptors will always adopt the first ballot number they receive. If $b' \leq_\mathcal{B} b$ then the acceptor will adopt this new ballot number, that is set $b' := b$. In either case, the acceptor will reply with a \texttt{phase1b($b'$, pvals)} message, where $\textrm{pvals}$ is the set of pvalues previously accepted. \\

If a leader receives \texttt{phase1b($b'$, pvals)} from a majority quorum of acceptors and if $b = b'$ then it will proceed with phase 2 of the protocol. Otherwise the leader abandons the proposal, increments the round number of its ballot number and tries again. Likewise if a leader receives a response where $b' \neq b$ then it should restart the protocol with a higher round number. \\

\textbf{Phase 2a} Leaders then attempt to commit a given pvalue $\left( b, s, c \right)$ by broadcasting a \texttt{phase2a($b,s,c$)} message to the acceptors. \\

\textbf{Phase 2b} Acceptors receiving a \texttt{phase2a($b,s,c$)} will compare $b$ to their adopted ballot number $b'$. If $b = b'$ then they will accept the pvalue $(b,s,c)$; otherwise they do not change their state. In either case they reply with a  \texttt{phase2b($b'$)} message. \\

Leaders will again wait for receipt of a \texttt{phase2b($b'$)} from a majority quorum of acceptors. If $b = b'$ then they know the acceptor has accepted the pvalue and so broadcast a \texttt{decision($s,c$)} message to the set of replicas so they can commit command $c$ to slot $s$. Otherwise if $b \neq b'$ then a leader knows the acceptor has since adopted a different leader's ballot number and so should restart the protocol with a higher round number.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Requirements}

\subsection{System requirements}

As previously noted, there are a number of papers that describe Paxos and its variants. Each presents the algorithm differently and nearly all of them present it theoretically, with little concern for functionality required in software. Implementation details are often entirely overlooked. Hence it is necessary to recognise both the theoretical requirements from the literature as well as identify additional functionality required to realise the algorithm as functioning software. \\

A \emph{requirements analysis} of the final system was therefore performed. Information was collected from the literature about how the algorithm worked at a high--level before considering the practical functionality. This is gathered into the final system requirements listed below. \\

\textbf{General requirements}
\begin{itemize}
  \item The ability to pass the executable file command line arguments for initialisation.
  \item Ability for each process to be nominated to, and start up in, a given role.
  \item Configuration files that contain the network addresses of each of the processes participating. Each process must be able to parse such a configuration file.
  \item The ability to log important information to disk or direct to \texttt{stdout} / \texttt{stderr}. The ability to log different information (e.g. debugging info versus error info) to different files.
\end{itemize}

\textbf{Messaging subsystem}
\begin{itemize}
  \item Provide an abstraction so processes can send messages without concern of the underlying network.
  \item Send messages as required by the Multi--Paxos algorithm. Ability to serialise and deserialise arguments and results.
  \item Mask failures in the network from processes.
\end{itemize}

\textbf{Application requirements}
\begin{itemize}
  \item A key--value store application that can be modelled as a state machine. This needs to have commands to create key--value pairs, update key--values pairs, read a value for a given key and delete a key--value pair for a given key.
  \item The store must be strongly consistent across all replicas.
\end{itemize}

\textbf{Consensus algorithm requirements}
\begin{itemize}
  \item Client processes that can send commands to replicas and receive responses.
  \item Replicas that each maintain a strongly consistent copy of the application state. They must receive requests from clients and each attempt to propose their own serialisation of the requests to leaders.
  \item Leaders and acceptors take part in the synod protocol to produces a consistent serialisation of the commands proposed by replicas.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Software engineering}

This section gives detail on the software development pratices and related work that was undertaken before development commenced. The methods, third party libraries, tools and test strategies that were employed to manage the project and improve productivity are discussed.

\subsection{Starting point}

The starting point of this project is the same as that described in the Project Proposal reproduced in Appendix \ref{appendix:proposal}.

\subsection{Methodology}

The method by which the software was developed was to split the system into its logical constituents and develop each in turn, with as much independence from the each other as possible. To facilitate this, having been informed by the requirements, I deemed it necessary to separate the messaging system from the actual operation of Multi--Paxos itself. \\

This messaging system was the first module developed and was incrementally equipped with functionality that facilitated the rest of the program. The next logical division was to separate the operation of clients and replicas from that of leaders and acceptors. Clients, replicas and associated functionality were developed first followed by that of leaders and acceptors in two development phases. \\

\subsection{Libraries}

OCaml has a large ecosystem of third party libraries available. They are used where it is necessary to avoid writing large bodies of code for common tasks. This project uses the OPAM\footnote{https://opam.ocaml.org} package manager to install, update and manage the libraries used. \\ 

A library of particular interest to this project is that which provides RPCs (Remote Procedure Calls). Cap'n Proto\footnote{https://capnproto.org/} was chosen as it has good support and documentation for its OCaml bindings\footnote{https://github.com/capnproto/capnp-ocaml, https://github.com/mirage/capnp-rpc}. \\

Lwt\footnote{https://github.com/ocsigen/lwt} is a monadic concurrency library chosen for this project. It leverages the type system to express the promise of a computation as a \emph{monad} of type \texttt{'a Lwt.t}. This library was chosen because it has thorough documentation and interoperates with Cap'n Proto. \\

This project also uses Core\footnote{https://github.com/janestreet/core} on top of the standard library, providing useful functions and enriching others already present. Yojson\footnote{https://github.com/mjambon/yojson} was used for serialisation into JSON. OUnit\footnote{http://ounit.forge.ocamlcore.org/} was used to manage unit testing for this project, discussed in \S\ref{subsection-testing}. Uri\footnote{https://github.com/mirage/ocaml-uri} was used to format URIs. \\

In the case of each library used their software license was available either through OPAM or the library's Github repository. {\color{red}YoJson required reproduction of their licensing information be distributed with the project}. Appendix \ref{appendix:licenses} gives details of each library's software license.

\subsection{Tools}
  
Choice of tools is important for being productive in a language. MacVim\footnote{https://github.com/macvim-dev/macvim} was used as a text editor. Merlin was used to provide code--completion and edit--time type inference features within MacVim. \\ 

Git was used for source control and versioning, with branches made for each new feature under development and merged back into the master. Backups were made to a remote repository on Github and periodically to Google Drive. All of the development work was undertaken on my personal machine with the option of fallback onto the MCS machines. \\

A network simulator was used to simulate the operation and performance of the implementation. Mininet\footnote{http://mininet.org/}, the simulator used in this project, uses process based virtualisation thats allows for arbitrary processes to be run on hosts on a virtual network. Mininet provides a complete Python API for setting up such simulations and performing experiments. Mininet required use of VirtualBox\footnote{https://www.virtualbox.org/}, virtualization software that allowed Mininet to be used on my own machine.

\subsection{Build system}
JBuilder was used as the build system for this project. It was chosen for its minimal configuration files (called \emph{jbuild} files), automatic linking of OPAM packages and generation of \texttt{.merlin} files. It is also able to automatically run the Cap'n Proto code generator upon building.

\subsection{Testing}
\label{subsection-testing}
Unit testing was performed in order to check the operation of functions at a fine--grained level within the program. OCaml's static type system ensures the compiler will catch a number of errors resulting from improper calls to functions and so unit tests were designed as a complement to this; tests focussed on correctly typed arguments to functions yielding appropriate results. The test suites were executed after successful builds of the project.

\section{Summary}
This chapter discussed the theoretical basis for implementing Multi--Paxos and state machine replication before going on to describe a set of requirements for an implementation of the algorithm, finishing with a description of the software engineering tools and techniques employed. With this in place it is possible to go on to describe the implementation of the algorithm and its underlying systems in Chapter 3.




